{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#%% import\n",
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import ast\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw \n",
    "from tqdm import tqdm\n",
    "from dask import bag\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfiles = os.listdir('./train_simplified/')\n",
    "numstonames = {i: v[:-4].replace(\" \", \"_\") for i, v in enumerate(classfiles)}\n",
    "\n",
    "num_classes = 340\n",
    "imheight, imwidth = 32, 32\n",
    "ims_per_class = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [05:09<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    image = Image.new(\"P\", (256,256), color=255)\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0])-1):\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=0, width=5)\n",
    "    image = image.resize((imheight, imwidth))\n",
    "    return np.array(image)/255.\n",
    "\n",
    "train_grand = []\n",
    "class_paths = glob('./train_simplified/*.csv')\n",
    "for i,c in enumerate(tqdm(class_paths[0:num_classes])):\n",
    "# for i,c in enumerate(tqdm(class_paths[0:2])):\n",
    "    train = pd.read_csv(c, usecols=['drawing', 'recognized'], nrows=ims_per_class*5//4)\n",
    "    train = train[train.recognized == True].head(ims_per_class)\n",
    "    imagebag = bag.from_sequence(train.drawing.values).map(draw_it)\n",
    "    trainarray = np.array(imagebag.compute())\n",
    "    trainarray = np.reshape(trainarray, (ims_per_class, -1))\n",
    "    labelarray = np.full((train.shape[0], 1), i)\n",
    "    trainarray = np.concatenate((labelarray, trainarray), axis=1)\n",
    "    train_grand.append(trainarray)\n",
    "\n",
    "# print(type(train_grand))\n",
    "train_grand = np.array([train_grand.pop() for i in np.arange(num_classes)])\n",
    "# print(type(train_grand))\n",
    "train_grand = train_grand.reshape((-1, (imheight*imwidth+1)))\n",
    "# print(type(train_grand))\n",
    "\n",
    "del trainarray\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612000,)\n",
      "(612000, 1024)\n",
      "(68000,)\n",
      "(68000, 1024)\n",
      "(612000, 340) \n",
      " (612000, 32, 32, 1) \n",
      " (68000, 340) \n",
      " (68000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "valfrac = 0.1\n",
    "\n",
    "# print(train_grand.shape[0])\n",
    "cutpt = int(valfrac * train_grand.shape[0])\n",
    "# print(cutpt)\n",
    "\n",
    "np.random.shuffle(train_grand)\n",
    "y_train, X_train = train_grand[cutpt: , 0], train_grand[cutpt:, 1:]\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "y_val, X_val = train_grand[0:cutpt, 0], train_grand[0:cutpt, 1:]\n",
    "print(y_val.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "del train_grand\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "X_train = X_train.reshape(X_train.shape[0], imheight, imwidth, 1)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "X_val = X_val.reshape(X_val.shape[0], imheight, imwidth, 1)\n",
    "\n",
    "print(y_train.shape, \"\\n\",\n",
    "      X_train.shape, \"\\n\",\n",
    "      y_val.shape, \"\\n\",\n",
    "      X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 680)               2785960   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 680)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               231540    \n",
      "=================================================================\n",
      "Total params: 3,036,316\n",
      "Trainable params: 3,036,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(imheight, imwidth, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(680, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 612000 samples, validate on 68000 samples\n",
      "Epoch 1/22\n",
      "612000/612000 [==============================] - 94s 154us/step - loss: 3.3640 - acc: 0.2726 - top_3_accuracy: 0.4455 - val_loss: 2.2731 - val_acc: 0.4548 - val_top_3_accuracy: 0.6641\n",
      "Epoch 2/22\n",
      "612000/612000 [==============================] - 91s 148us/step - loss: 2.5620 - acc: 0.3924 - top_3_accuracy: 0.6033 - val_loss: 2.0749 - val_acc: 0.4950 - val_top_3_accuracy: 0.7058\n",
      "Epoch 3/22\n",
      "612000/612000 [==============================] - 91s 149us/step - loss: 2.4146 - acc: 0.4194 - top_3_accuracy: 0.6332 - val_loss: 1.9708 - val_acc: 0.5120 - val_top_3_accuracy: 0.7244\n",
      "Epoch 4/22\n",
      "612000/612000 [==============================] - 91s 149us/step - loss: 2.3418 - acc: 0.4347 - top_3_accuracy: 0.6487 - val_loss: 1.9401 - val_acc: 0.5215 - val_top_3_accuracy: 0.7335\n",
      "Epoch 5/22\n",
      "612000/612000 [==============================] - 92s 150us/step - loss: 2.3012 - acc: 0.4424 - top_3_accuracy: 0.6567 - val_loss: 1.9305 - val_acc: 0.5244 - val_top_3_accuracy: 0.7359\n",
      "Epoch 6/22\n",
      "612000/612000 [==============================] - 91s 149us/step - loss: 2.2736 - acc: 0.4476 - top_3_accuracy: 0.6621 - val_loss: 1.9188 - val_acc: 0.5274 - val_top_3_accuracy: 0.7344\n",
      "Epoch 7/22\n",
      "612000/612000 [==============================] - 91s 148us/step - loss: 2.2532 - acc: 0.4525 - top_3_accuracy: 0.6667 - val_loss: 1.9085 - val_acc: 0.5337 - val_top_3_accuracy: 0.7423\n",
      "Epoch 8/22\n",
      "612000/612000 [==============================] - 92s 150us/step - loss: 2.2408 - acc: 0.4541 - top_3_accuracy: 0.6687 - val_loss: 1.8914 - val_acc: 0.5366 - val_top_3_accuracy: 0.7448\n",
      "Epoch 9/22\n",
      "612000/612000 [==============================] - 92s 150us/step - loss: 2.2333 - acc: 0.4566 - top_3_accuracy: 0.6713 - val_loss: 1.9021 - val_acc: 0.5296 - val_top_3_accuracy: 0.7387\n",
      "Epoch 10/22\n",
      "612000/612000 [==============================] - 93s 152us/step - loss: 2.2278 - acc: 0.4575 - top_3_accuracy: 0.6728 - val_loss: 1.8728 - val_acc: 0.5372 - val_top_3_accuracy: 0.7442\n",
      "Epoch 11/22\n",
      "612000/612000 [==============================] - 111s 182us/step - loss: 2.2232 - acc: 0.4587 - top_3_accuracy: 0.6730 - val_loss: 1.8758 - val_acc: 0.5338 - val_top_3_accuracy: 0.7442\n",
      "Epoch 12/22\n",
      "612000/612000 [==============================] - 111s 182us/step - loss: 2.2176 - acc: 0.4600 - top_3_accuracy: 0.6745 - val_loss: 1.9439 - val_acc: 0.5255 - val_top_3_accuracy: 0.7354\n",
      "Epoch 13/22\n",
      "612000/612000 [==============================] - 112s 182us/step - loss: 2.2178 - acc: 0.4597 - top_3_accuracy: 0.6750 - val_loss: 1.9244 - val_acc: 0.5315 - val_top_3_accuracy: 0.7399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f45781407b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_3_accuracy(x, y):\n",
    "    t3 = top_k_categorical_accuracy(x, y, 3)\n",
    "    return t3\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='auto', cooldown=5, min_lr=0.0001)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_top_3_accuracy', mode='max', patience=5)\n",
    "callbacks = [reduceLROnPlat, earlystop]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy', top_3_accuracy])\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=22, \n",
    "          validation_data=(X_val, y_val), callbacks=callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:25<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "ttvlist = []\n",
    "reader = pd.read_csv('./test_simplified.csv', index_col=['key_id'],\n",
    "    chunksize=2048)\n",
    "for chunk in tqdm(reader, total=55):\n",
    "    imagebag = bag.from_sequence(chunk.drawing.values).map(draw_it)\n",
    "    testarray = np.array(imagebag.compute())\n",
    "    testarray = np.reshape(testarray, (testarray.shape[0], imheight, imwidth, 1))\n",
    "    testpreds = model.predict(testarray, verbose=0)\n",
    "    ttvs = np.argsort(-testpreds)[:, 0:3]  # top 3\n",
    "    ttvlist.append(ttvs)\n",
    "\n",
    "ttvarray = np.concatenate(ttvlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9000003627287624</th>\n",
       "      <td>nose remote_control peas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000010688666847</th>\n",
       "      <td>crocodile hot_tub bulldozer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000023642890129</th>\n",
       "      <td>lollipop telephone pond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000038588854897</th>\n",
       "      <td>ceiling_fan face stethoscope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000052667981386</th>\n",
       "      <td>bowtie firetruck sea_turtle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          word\n",
       "key_id                                        \n",
       "9000003627287624      nose remote_control peas\n",
       "9000010688666847   crocodile hot_tub bulldozer\n",
       "9000023642890129       lollipop telephone pond\n",
       "9000038588854897  ceiling_fan face stethoscope\n",
       "9000052667981386   bowtie firetruck sea_turtle"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = pd.DataFrame({'first': ttvarray[:,0], 'second': ttvarray[:,1], 'third': ttvarray[:,2]})\n",
    "preds_df = preds_df.replace(numstonames)\n",
    "preds_df['words'] = preds_df['first'] + \" \" + preds_df['second'] + \" \" + preds_df['third']\n",
    "\n",
    "sub = pd.read_csv('./sample_submission.csv', index_col=['key_id'])\n",
    "sub['word'] = preds_df.words.values\n",
    "sub.to_csv('subcnn_small.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preds_df', 30114166),\n",
       " ('sub', 9671503),\n",
       " ('ttvarray', 2692888),\n",
       " ('chunk', 1053432),\n",
       " ('testpreds', 218664),\n",
       " ('labelarray', 16112),\n",
       " ('numstonames', 9320),\n",
       " ('class_paths', 3104),\n",
       " ('Sequential', 3096),\n",
       " ('classfiles', 2896),\n",
       " ('Dense', 2000),\n",
       " ('Dropout', 2000),\n",
       " ('Flatten', 2000),\n",
       " ('MaxPooling2D', 2000),\n",
       " ('EarlyStopping', 1464),\n",
       " ('ReduceLROnPlateau', 1464),\n",
       " ('ModelCheckpoint', 1056),\n",
       " ('Conv2D', 888),\n",
       " ('ttvlist', 528),\n",
       " ('X_train', 144),\n",
       " ('X_val', 144),\n",
       " ('testarray', 144),\n",
       " ('draw_it', 136),\n",
       " ('top_3_accuracy', 136),\n",
       " ('top_k_categorical_accuracy', 136),\n",
       " ('ttvs', 112),\n",
       " ('y_train', 112),\n",
       " ('y_val', 112),\n",
       " ('c', 81),\n",
       " ('Image', 80),\n",
       " ('ImageDraw', 80),\n",
       " ('bag', 80),\n",
       " ('callbacks', 80),\n",
       " ('keras', 80),\n",
       " ('np', 80),\n",
       " ('pd', 80),\n",
       " ('tf', 80),\n",
       " ('earlystop', 56),\n",
       " ('imagebag', 56),\n",
       " ('model', 56),\n",
       " ('reader', 56),\n",
       " ('reduceLROnPlat', 56),\n",
       " ('cutpt', 28),\n",
       " ('i', 28),\n",
       " ('imheight', 28),\n",
       " ('ims_per_class', 28),\n",
       " ('imwidth', 28),\n",
       " ('num_classes', 28),\n",
       " ('valfrac', 24)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not \n",
    "    x.startswith('_') and x not in sys.modules and x \n",
    "    not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
